wandb:
  params:
    run_name: lgai-exaone-exaone-4.0-1.2b_reasoning

model:
  name: litellm
  params:
    model_name: "LGAI-EXAONE/EXAONE-4.0-1.2B"
    provider: hosted_vllm
    api_base: http://localhost:9108/v1
    batch_size: 8
    max_tokens: 8192
    temperature: 0.6
    top_p: 0.95
    extra_body:
      chat_template_kwargs:
        enable_thinking: true
        skip_think: false

  vllm_params:
    batch_size: 16
    dtype: "auto"
    download_dir: "/dataset/models/huggingface/hub"
    max_model_len: 65536
    num_gpus: 1
    port: 9108
    pretrained_model_name_or_path: "LGAI-EXAONE/EXAONE-4.0-1.2B"
    tensor_parallel_size: 1
    trust_remote_code: true
    reasoning_parser: deepseek_r1
    
  release_date: "2025-07-15"
  model_size: 1200000000
  size_category: "Small (<10B)"

bfcl:
  model_params:
    max_tokens: 8192
    temperature: 0.6
    model_name: "LGAI-EXAONE/EXAONE-4.0-1.2B"
