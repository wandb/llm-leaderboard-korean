wandb:
  params:
    run_name: "gemma-3-27b-it"

model:
  name: litellm
  params:
    model_name: google/gemma-3-27b-it
    provider: hosted_vllm
    api_base: http://localhost:8010/v1
    batch_size: 8
    max_tokens: 1024
    temperature: 0.1
  vllm_params:
    batch_size: 16
    dtype: "auto"
    download_dir: "/workspace/huggingface/hub"
    max_model_len: 131072
    num_gpus: 1
    port: 8010
    pretrained_model_name_or_path: "google/gemma-3-27b-it"
    tensor_parallel_size: 1
    trust_remote_code: true
  release_date: "2025-03-12"
  model_size: 27432406640
  size_category: "Medium (10â€“30B)"

bfcl:
  model_params:
    max_tokens: 1024
    temperature: 0.1
    model_name: gemma-3-27b-it