# =============================================================================
# LiquidAI LFM-2.5-1.2B-Thinking (OpenRouter Free)
# https://openrouter.ai/liquid/lfm-2.5-1.2b-thinking:free
# =============================================================================

# W&B Settings
wandb:
  run_name: "LFM-2.5-1.2B-Thinking"

# Model Metadata
metadata:
  release_date: "2026-01-20"
  size_category: "Small (<10B)"
  model_size: 1200000000              # 1.2B parameters
  active_params: 1200000000           # Dense model
  context_window: 32768

# =============================================================================
# Model Configuration
# =============================================================================

model:
  # OpenRouter 모델명
  name: liquid/lfm-2.5-1.2b-thinking

  # API Client
  client: litellm

  # Model Provider
  provider: openrouter

  # Environment variable name for API key
  api_key_env: OPENROUTER_API_KEY

  # Generation Parameters
  params:
    max_tokens: 8192
    temperature: 0.6
    top_p: 0.95
    timeout: 3600
    max_retries: 5


# =============================================================================
# Benchmark-specific Overrides
# =============================================================================

benchmarks:
  bfcl:
    use_native_tools: false            # OpenRouter tool calling 호환 이슈 방지
