# Kanana 2 30B A3B Instruct (vLLM, OpenAI-Compatible)

wandb:
  run_name: "HyperCLOVAX-SEED-Think-32B"

metadata:
  release_date: "2025-12-26"
  size_category: "Large (30B<)"
  model_size: 32000000000
  active_params: 30000000000
  context_window: 128000

# vLLM Server Auto-Start Configuration
# If present, run_eval.py will automatically start/stop vLLM server
vllm:
  model_path: "naver-hyperclovax/HyperCLOVAX-SEED-Think-32B"
  tensor_parallel_size: 2
  port: 8000
  host: "0.0.0.0"
  max_model_len: 64000
  trust_remote_code: true
  served_model_name: "HyperCLOVAX-SEED-Think-32B"
  enable_auto_tool_choice: true
  tool_call_parser: "hermes"

model:
  name: HyperCLOVAX-SEED-Think-32B
  client: litellm
  provider: hosted_vllm
  base_url: "http://localhost:8000/a/v1"
  api_key_env: HOSTED_VLLM_API_KEY

  params:
    max_tokens: 64000
    temperature: 0.7
    timeout: 7200
    max_retries: 10

benchmarks:
  bfcl:
    use_native_tools: false  # vLLM tool_calls 형식 호환성 문제로 text-based 사용