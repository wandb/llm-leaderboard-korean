# hrm8k_openai_eval.yaml
# Usage:
#   python -m llm_eval.evaluator --config path/to/this/file.yaml

# Dataset settings
dataset:
  name: "hrm8k"
  subset: null  # null로 두면 모든 subset(GSM8K, KSM, MATH 등)을 평가합니다.
  split: "test"
  params: {} # 데이터셋의 기본 프롬프트 템플릿을 사용합니다.

# Model backend
model:
  name: "openai"
  params:
    model_name: "[여기에 평가할 모델 이름을 입력하세요]"
    api_base: "[여기에 API 엔드포인트 URL을 입력하세요]"
    max_new_tokens: 1024
    temperature: 0.0
    cot: true # 모델이 풀이 과정을 생성하도록 유도합니다.

# No judge or reward models
judge_model:
  name: null
  params: {}

reward_model:
  name: null
  params: {}

# No scaling by default
scaling:
  name: null
  params: {}

# Evaluation method
evaluation:
  method: "math_match"
  params:
    extract_final_answer: true # 답변에서 최종 수식/결과를 추출합니다.

# Global options
language_penalize: false
target_lang: "en"
custom_cot_parser: null

# Few-shot (optional)
few_shot:
  num: 0
  split: null
  instruction: "Use the following examples to answer the question."
  example_template: |
    Q: {input}
    A: {reference}